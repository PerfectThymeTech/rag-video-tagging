{
	"name": "CopyAndUnzip",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "spark34",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "99e2c290-4a59-4450-b7d0-d4a54f7ad12a"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/8f171ff9-2b5b-4f0f-aed5-7fa360a1d094/resourceGroups/test-purview/providers/Microsoft.Synapse/workspaces/tstsynapse4/bigDataPools/spark34",
				"name": "spark34",
				"type": "Spark",
				"endpoint": "https://tstsynapse4.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/spark34",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.4",
				"nodeCount": 10,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"metadata": {
					"tags": [
						"parameters"
					]
				},
				"source": [
					"# General parameters\n",
					"delete_source_file = True\n",
					"exit_notebook_with_outputs = True\n",
					"\n",
					"# Source storage parameters\n",
					"source_account_name = \"tstsynapsestg\"\n",
					"source_container_name = \"external\"\n",
					"source_directory_name = \"\"\n",
					"source_file_name = \"myarchive.zip\"\n",
					"\n",
					"# Sink storage parameters\n",
					"sink_account_name = \"tstsynapsestg\"\n",
					"sink_container_name = \"raw\"\n",
					"sink_directory_name = \"\"\n",
					"sink_linked_service_name = \"DataLakeRaw\"\n",
					""
				],
				"execution_count": 35
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Get Pipeline ID"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import logging\n",
					"import uuid\n",
					"from notebookutils import mssparkutils\n",
					"\n",
					"pipeline_id = mssparkutils.runtime.context.get(\"pipelinejobid\")\n",
					"if not pipeline_id:\n",
					"    pipeline_id = f\"{uuid.uuid4()}\"\n",
					"\n",
					"logging.info(f\"Pipeline ID: '{pipeline_id}'\")"
				],
				"execution_count": 36
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"print(f\"Pipeline ID: '{pipeline_id}'\")"
				],
				"execution_count": 37
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Copy Archive"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Define source file path\n",
					"source_adls_path = f\"abfss://{source_container_name}@{source_account_name}.dfs.core.windows.net/{source_directory_name}/{source_file_name}\"\n",
					"\n",
					"# Define sink file path\n",
					"source_file_extension = source_file_name.split(\".\")[-1]\n",
					"sink_directory_name_adls = f\"{pipeline_id}/{sink_directory_name}\"\n",
					"sink_file_name_adls = f\"archive.{source_file_extension}\"\n",
					"sink_adls_path = f\"abfss://{sink_container_name}@{sink_account_name}.dfs.core.windows.net/{sink_directory_name_adls}/{sink_file_name_adls}\"\n",
					""
				],
				"execution_count": 38
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"mssparkutils.fs.fastcp(\n",
					"    src=source_adls_path,\n",
					"    dest=sink_adls_path,\n",
					"    recurse=False\n",
					")\n",
					""
				],
				"execution_count": 39
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"if delete_source_file:\n",
					"    mssparkutils.fs.rm(\n",
					"        dir=source_adls_path,\n",
					"        recurse=False\n",
					"    )\n",
					""
				],
				"execution_count": 40
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Unzip Archive"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"from notebookutils import mssparkutils\n",
					"\n",
					"\n",
					"def mount_datalake_gen2(account_name: str, container_name: str, mount_path: str, linked_service_name: str) -> str:\n",
					"    # Mount ADLS Gen2\n",
					"    mssparkutils.fs.mount( \n",
					"        f\"abfss://{container_name}@{account_name}.dfs.core.windows.net\", \n",
					"        f\"/{mount_path}\",\n",
					"        {\n",
					"            \"LinkedService\": linked_service_name,\n",
					"            \"fileCacheTimeout\": 120,\n",
					"            \"timeout\": 120\n",
					"        }\n",
					"    )\n",
					"\n",
					"    # Compute mount point and return value\n",
					"    mount_path_cluster = mssparkutils.fs.getMountPath(f\"/{mount_path}\")\n",
					"    return mount_path_cluster\n",
					"\n",
					"\n",
					"def unmount_datalake_gen2(mount_path: str) -> None:\n",
					"    mssparkutils.fs.unmount(f\"/{mount_path}\")\n",
					""
				],
				"execution_count": 41
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Mount destination path storage\n",
					"sink_mount_path = \"sink\"\n",
					"sink_mount_path_cluster = mount_datalake_gen2(\n",
					"    account_name=sink_account_name,\n",
					"    container_name=sink_container_name,\n",
					"    mount_path=sink_mount_path,\n",
					"    linked_service_name=sink_linked_service_name,\n",
					")\n",
					""
				],
				"execution_count": 42
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import subprocess\n",
					"\n",
					"archive_file_path = f\"{sink_mount_path_cluster}/{sink_directory_name_adls}/{sink_file_name_adls}\"\n",
					"unzip_sink_path = f\"{sink_mount_path_cluster}/{sink_directory_name_adls}/\"\n",
					"\n",
					"res = subprocess.run([\"unzip\", archive_file_path, \"-d\", unzip_sink_path])\n",
					"\n",
					"try:\n",
					"    res.check_returncode()\n",
					"except subprocess.CalledProcessError as e:\n",
					"    logging.error(f\"Failed to unzip archive in sink '{e}'.\")\n",
					""
				],
				"execution_count": 43
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"if delete_source_file:\n",
					"    mssparkutils.fs.rm(\n",
					"        dir=sink_adls_path,\n",
					"        recurse=False\n",
					"    )\n",
					""
				],
				"execution_count": 44
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Unmount sink storage\n",
					"unmount_datalake_gen2(\n",
					"    mount_path=sink_mount_path,\n",
					")\n",
					""
				],
				"execution_count": 45
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Create outputs"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"outputs = {\n",
					"    \"sink_adls_path\": sink_adls_path,\n",
					"    \"sink_account_name\": sink_account_name,\n",
					"    \"sink_container_name\": sink_container_name,\n",
					"    \"sink_directory_name\": f\"{sink_directory_name_adls}/\"\n",
					"}\n",
					"\n",
					"if exit_notebook_with_outputs:\n",
					"    mssparkutils.notebook.exit(\n",
					"        value=str(outputs)\n",
					"    )\n",
					""
				],
				"execution_count": 47
			}
		]
	}
}